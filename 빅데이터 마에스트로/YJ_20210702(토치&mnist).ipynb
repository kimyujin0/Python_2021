{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64fb08b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51fa6e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1차원 텐서\n",
    "z = torch.FloatTensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d4ecf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0900, 0.2447, 0.6652])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis = F.softmax(z, dim=0)\n",
    "hypothesis\n",
    "# softmax : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91dcbe45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09003057317038046"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.exp(1.0)/(np.exp(1.0)+np.exp(2.0)+np.exp(3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1e0123d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24472847105479767"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(2.0)/(np.exp(1.0)+np.exp(2.0)+np.exp(3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bddf2ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6652409557748219"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(3.0)/(np.exp(1.0)+np.exp(2.0)+np.exp(3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d731e884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b46462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST(손글씨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edd6dce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\programdata\\anaconda3\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.20.1)\n",
      "Requirement already satisfied: torch==1.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.9.0)\n",
      "Requirement already satisfied: pillow>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (8.2.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==1.9.0->torchvision) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cddc82a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn as nn\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b57cc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "mnist_train = dsets.MNIST(root='MNIST_data/', train = True, transform = transforms.ToTensor(), download=True)\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/', train = False, transform = transforms.ToTensor(), download=True)\n",
    "\n",
    "training_epochs = 15\n",
    "batch_size=100\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b948e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e599661e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 9\n"
     ]
    }
   ],
   "source": [
    "image,label=mnist_train[4]\n",
    "print(image.shape,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2e0e5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#plt.imshow(image.reshape(28,28),cmalp='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e3147a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(28*28,10, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c540f594",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f960de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.535338283\n",
      "Epoch: 0002 cost= 0.358997613\n",
      "Epoch: 0003 cost= 0.331037134\n",
      "Epoch: 0004 cost= 0.316336066\n",
      "Epoch: 0005 cost= 0.306966811\n",
      "Epoch: 0006 cost= 0.300216109\n",
      "Epoch: 0007 cost= 0.294924527\n",
      "Epoch: 0008 cost= 0.290726393\n",
      "Epoch: 0009 cost= 0.287327200\n",
      "Epoch: 0010 cost= 0.284433603\n",
      "Epoch: 0011 cost= 0.281728476\n",
      "Epoch: 0012 cost= 0.279644251\n",
      "Epoch: 0013 cost= 0.277889937\n",
      "Epoch: 0014 cost= 0.276031733\n",
      "Epoch: 0015 cost= 0.274234921\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    total_batch = len(data_loader)\n",
    "    avg_cost=0\n",
    "    for X,y in data_loader:\n",
    "        X = X.view(-1, 28*28)\n",
    "        y = y\n",
    "        \n",
    "        hypothesis = linear(X)\n",
    "        cost = criterion(hypothesis, y)\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost/total_batch\n",
    "    print('Epoch:','%04d' %(epoch+1),'cost=',\"{:.9f}\".format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "833755eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.272991747\n",
      "Epoch: 0002 cost= 0.271515787\n",
      "Epoch: 0003 cost= 0.270323426\n",
      "Epoch: 0004 cost= 0.269373953\n",
      "Epoch: 0005 cost= 0.268347412\n",
      "Epoch: 0006 cost= 0.267241806\n",
      "Epoch: 0007 cost= 0.266196340\n",
      "Epoch: 0008 cost= 0.265709639\n",
      "Epoch: 0009 cost= 0.264909565\n",
      "Epoch: 0010 cost= 0.263964653\n",
      "Epoch: 0011 cost= 0.263359725\n",
      "Epoch: 0012 cost= 0.262617648\n",
      "Epoch: 0013 cost= 0.261664331\n",
      "Epoch: 0014 cost= 0.261212498\n",
      "Epoch: 0015 cost= 0.260706246\n"
     ]
    }
   ],
   "source": [
    "for epoch in range (training_epochs):\n",
    "    avg_cost=0\n",
    "    total_batch = len(data_loader)\n",
    "    \n",
    "    for X,y in data_loader:\n",
    "        X = X.view(-1,28*28)\n",
    "        y = y\n",
    "        \n",
    "        hypothesis = linear(X)\n",
    "        cost = criterion(hypothesis, y)\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost/total_batch #하나씩 증가할 때마다 나눠서 보여줌\n",
    "\n",
    "    print('Epoch:','%04d' %(epoch+1), 'cost=', \"{:.9f}\".format(avg_cost)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0eaab4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8765000104904175\n",
      "Label: 0\n",
      "Prediction: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:67: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:57: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "view() received an invalid combination of arguments - got (), but expected one of:\n * (tuple of ints size)\n * (torch.dtype dtype)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-a8e3cef61031>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Prediction:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msingle_prediction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: view() received an invalid combination of arguments - got (), but expected one of:\n * (tuple of ints size)\n * (torch.dtype dtype)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_test =mnist_test.test_data.view(-1,28*28).float()\n",
    "    y_test =mnist_test.test_labels\n",
    "    \n",
    "    prediction = linear(X_test)\n",
    "    \n",
    "    correct_prediction = torch.argmax(prediction,1)==y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print(\"acc:\",accuracy.item())\n",
    "    r = random.randint(0,len(mnist_test)-1)\n",
    "    X_single_data = mnist_test.test_data[r:r+1].view(-1,28*28).float()\n",
    "    y_single_data = mnist_test.test_labels[r:r+1]\n",
    "    print('Label:',y_single_data.item())\n",
    "    single_prediction = linear(X_single_data)\n",
    "    print('Prediction:', torch.argmax(single_prediction,1).item())\n",
    "    \n",
    "#plt.imshow(mnist_test.test_data[r:r+1].view())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31be6a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network - Deep learnig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110fb27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layering\n",
    "# nn.Linear(784,10) 784->10\n",
    "# 784->256->256->10  (레이어를 천천히 줄임)\n",
    "linear1 = nn.Linear(784,256,bias=True)\n",
    "linear2 = nn.Linear(256,256,bias=True)\n",
    "linear3 = nn.Linear(256,10,bias=True)\n",
    "relu = torch.nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f1eba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.init.normal_(linear1.weight)  # 초기화 : 0으로 시작\n",
    "nn.init.normal_(linear2.weight)\n",
    "nn.init.normal_(linear3.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece66022",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(linear1, relu, linear2, relu, linear3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623e4125",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer= torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "total_batch = len(data_loader)\n",
    "train_epochs = 15\n",
    "batch_size =100\n",
    "for epoch in range(train_epochs):\n",
    "    avg_cost = 0\n",
    "    for X,y in data_loader:\n",
    "        X=X.view(-1,28*28)\n",
    "        y=y\n",
    "        optimizer.zero_grad()\n",
    "        hyp = model(X)\n",
    "        cost = criterion(hyp, y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        avg_cost +=cost/total_batch\n",
    "    print('Epoch:', '%04d'%(epoch+1), 'cost=','{:0.9f}'.format(avg_cost))\n",
    "print('End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c474aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    X_test =mnist_test.test_data.view(-1,28*28).float()\n",
    "    y_test =mnist_test.test_labels\n",
    "    \n",
    "    prediction = linear(X_test)\n",
    "    \n",
    "    correct_prediction = torch.argmax(prediction,1)==y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print(\"acc:\",accuracy.item())\n",
    "    r = random.randint(0,len(mnist_test)-1)\n",
    "    X_single_data = mnist_test.test_data[r:r+1].view(-1,28*28).float()\n",
    "    y_single_data = mnist_test.test_labels[r:r+1]\n",
    "    print('Label:',y_single_data.item())\n",
    "    single_prediction = linear(X_single_data)\n",
    "    print('Prediction:', torch.argmax(single_prediction,1).item())\n",
    "    \n",
    "#plt.imshow(mnist_test.test_data[r:r+1].view(28,28),cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
